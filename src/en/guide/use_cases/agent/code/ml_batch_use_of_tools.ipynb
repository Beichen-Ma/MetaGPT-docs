{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59e8271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:14:49.641876Z",
     "iopub.status.busy": "2024-01-30T07:14:49.641465Z",
     "iopub.status.idle": "2024-01-30T07:14:51.882361Z",
     "shell.execute_reply": "2024-01-30T07:14:51.880267Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493 entries, 0 to 492\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      493 non-null    object \n",
      " 1   AB      493 non-null    float64\n",
      " 2   AF      493 non-null    float64\n",
      " 3   AH      493 non-null    float64\n",
      " 4   AM      493 non-null    float64\n",
      " 5   AR      493 non-null    float64\n",
      " 6   AX      493 non-null    float64\n",
      " 7   AY      493 non-null    float64\n",
      " 8   AZ      493 non-null    float64\n",
      " 9   BC      493 non-null    float64\n",
      " 10  BD      493 non-null    float64\n",
      " 11  BN      493 non-null    float64\n",
      " 12  BP      493 non-null    float64\n",
      " 13  BQ      451 non-null    float64\n",
      " 14  BR      493 non-null    float64\n",
      " 15  BZ      493 non-null    float64\n",
      " 16  CB      492 non-null    float64\n",
      " 17  CC      492 non-null    float64\n",
      " 18  CD      493 non-null    float64\n",
      " 19  CF      493 non-null    float64\n",
      " 20  CH      493 non-null    float64\n",
      " 21  CL      493 non-null    float64\n",
      " 22  CR      493 non-null    float64\n",
      " 23  CS      493 non-null    float64\n",
      " 24  CU      493 non-null    float64\n",
      " 25  CW      493 non-null    float64\n",
      " 26  DA      493 non-null    float64\n",
      " 27  DE      493 non-null    float64\n",
      " 28  DF      493 non-null    float64\n",
      " 29  DH      493 non-null    float64\n",
      " 30  DI      493 non-null    float64\n",
      " 31  DL      493 non-null    float64\n",
      " 32  DN      493 non-null    float64\n",
      " 33  DU      492 non-null    float64\n",
      " 34  DV      493 non-null    float64\n",
      " 35  DY      493 non-null    float64\n",
      " 36  EB      493 non-null    float64\n",
      " 37  EE      493 non-null    float64\n",
      " 38  EG      493 non-null    float64\n",
      " 39  EH      493 non-null    float64\n",
      " 40  EJ      493 non-null    object \n",
      " 41  EL      452 non-null    float64\n",
      " 42  EP      493 non-null    float64\n",
      " 43  EU      493 non-null    float64\n",
      " 44  FC      493 non-null    float64\n",
      " 45  FD      493 non-null    float64\n",
      " 46  FE      493 non-null    float64\n",
      " 47  FI      493 non-null    float64\n",
      " 48  FL      492 non-null    float64\n",
      " 49  FR      493 non-null    float64\n",
      " 50  FS      492 non-null    float64\n",
      " 51  GB      493 non-null    float64\n",
      " 52  GE      493 non-null    float64\n",
      " 53  GF      493 non-null    float64\n",
      " 54  GH      493 non-null    float64\n",
      " 55  GI      493 non-null    float64\n",
      " 56  GL      492 non-null    float64\n",
      " 57  Class   493 non-null    int64  \n",
      "dtypes: float64(55), int64(1), object(2)\n",
      "memory usage: 223.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434b3925094e</td>\n",
       "      <td>0.354659</td>\n",
       "      <td>3315.29836</td>\n",
       "      <td>100.689104</td>\n",
       "      <td>51.823650</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.642116</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.121897</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>...</td>\n",
       "      <td>6.322717</td>\n",
       "      <td>1.71912</td>\n",
       "      <td>0.751803</td>\n",
       "      <td>16.980801</td>\n",
       "      <td>111.052214</td>\n",
       "      <td>9790.822836</td>\n",
       "      <td>34.947632</td>\n",
       "      <td>20.810052</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80ee5615ebdf</td>\n",
       "      <td>0.166647</td>\n",
       "      <td>3158.40492</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>17.937824</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.118368</td>\n",
       "      <td>0.058160</td>\n",
       "      <td>9.503416</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>...</td>\n",
       "      <td>10.110737</td>\n",
       "      <td>1.19509</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>6.297454</td>\n",
       "      <td>274.293492</td>\n",
       "      <td>12687.832390</td>\n",
       "      <td>15.628200</td>\n",
       "      <td>26.514748</td>\n",
       "      <td>0.070258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65de682cc48c</td>\n",
       "      <td>0.183739</td>\n",
       "      <td>2315.68106</td>\n",
       "      <td>98.019795</td>\n",
       "      <td>12.031845</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.936597</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>10.669286</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.128687</td>\n",
       "      <td>17.292418</td>\n",
       "      <td>252.824663</td>\n",
       "      <td>15889.416680</td>\n",
       "      <td>31.267563</td>\n",
       "      <td>57.792840</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>...</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89a5ed9b71a8</td>\n",
       "      <td>0.615312</td>\n",
       "      <td>4438.40947</td>\n",
       "      <td>188.889501</td>\n",
       "      <td>140.597606</td>\n",
       "      <td>8.453328</td>\n",
       "      <td>8.292024</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.570720</td>\n",
       "      <td>1.2299</td>\n",
       "      <td>...</td>\n",
       "      <td>5.457900</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>1.225913</td>\n",
       "      <td>23.031752</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>9756.985572</td>\n",
       "      <td>34.225758</td>\n",
       "      <td>48.713680</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id        AB          AF          AH          AM        AR  \\\n",
       "0  434b3925094e  0.354659  3315.29836  100.689104   51.823650  8.138688   \n",
       "1  80ee5615ebdf  0.166647  3158.40492   85.200147   17.937824  8.138688   \n",
       "2  65de682cc48c  0.183739  2315.68106   98.019795   12.031845  8.138688   \n",
       "3  043ac50845d5  0.252107  3819.65177  120.201618   77.112203  8.138688   \n",
       "4  89a5ed9b71a8  0.615312  4438.40947  188.889501  140.597606  8.453328   \n",
       "\n",
       "         AX        AY         AZ      BC  ...         FL       FR        FS  \\\n",
       "0  4.642116  0.025578  12.121897  1.2299  ...   6.322717  1.71912  0.751803   \n",
       "1  3.118368  0.058160   9.503416  1.2299  ...  10.110737  1.19509  0.067730   \n",
       "2  6.936597  0.025578  10.669286  1.2299  ...   0.173229  0.49706  0.128687   \n",
       "3  3.685344  0.025578  11.053708  1.2299  ...   6.122162  0.49706  0.284466   \n",
       "4  8.292024  0.025578   8.570720  1.2299  ...   5.457900  0.49706  1.225913   \n",
       "\n",
       "          GB          GE            GF         GH         GI         GL  Class  \n",
       "0  16.980801  111.052214   9790.822836  34.947632  20.810052   0.198000      0  \n",
       "1   6.297454  274.293492  12687.832390  15.628200  26.514748   0.070258      0  \n",
       "2  17.292418  252.824663  15889.416680  31.267563  57.792840  21.978000      0  \n",
       "3  18.529584   82.416803   2094.262452  39.948656  90.493248   0.155829      0  \n",
       "4  23.031752   72.611063   9756.985572  34.225758  48.713680   0.594000      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " BQ    42\n",
      "CB     1\n",
      "CC     1\n",
      "DU     1\n",
      "EL    41\n",
      "FL     1\n",
      "FS     1\n",
      "GL     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '434b3925094e'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 33\u001B[0m\n\u001B[1;32m     29\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# Step 5: Explore correlations between features\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# Calculate the correlation matrix\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m correlation_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Plot the correlation matrix using a heatmap\u001B[39;00m\n\u001B[1;32m     36\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/envs/metagpt_new/lib/python3.10/site-packages/pandas/core/frame.py:10054\u001B[0m, in \u001B[0;36mDataFrame.corr\u001B[0;34m(self, method, min_periods, numeric_only)\u001B[0m\n\u001B[1;32m  10052\u001B[0m cols \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[1;32m  10053\u001B[0m idx \u001B[38;5;241m=\u001B[39m cols\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m> 10054\u001B[0m mat \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m  10056\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpearson\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m  10057\u001B[0m     correl \u001B[38;5;241m=\u001B[39m libalgos\u001B[38;5;241m.\u001B[39mnancorr(mat, minp\u001B[38;5;241m=\u001B[39mmin_periods)\n",
      "File \u001B[0;32m~/anaconda3/envs/metagpt_new/lib/python3.10/site-packages/pandas/core/frame.py:1838\u001B[0m, in \u001B[0;36mDataFrame.to_numpy\u001B[0;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[1;32m   1836\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1837\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(dtype)\n\u001B[0;32m-> 1838\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtype:\n\u001B[1;32m   1840\u001B[0m     result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(result, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/anaconda3/envs/metagpt_new/lib/python3.10/site-packages/pandas/core/internals/managers.py:1732\u001B[0m, in \u001B[0;36mBlockManager.as_array\u001B[0;34m(self, dtype, copy, na_value)\u001B[0m\n\u001B[1;32m   1730\u001B[0m         arr\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1731\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1732\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interleave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1733\u001B[0m     \u001B[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001B[39;00m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;66;03m# to further copy if copy=True or setting na_value\u001B[39;00m\n\u001B[1;32m   1736\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[0;32m~/anaconda3/envs/metagpt_new/lib/python3.10/site-packages/pandas/core/internals/managers.py:1794\u001B[0m, in \u001B[0;36mBlockManager._interleave\u001B[0;34m(self, dtype, na_value)\u001B[0m\n\u001B[1;32m   1792\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1793\u001B[0m         arr \u001B[38;5;241m=\u001B[39m blk\u001B[38;5;241m.\u001B[39mget_values(dtype)\n\u001B[0;32m-> 1794\u001B[0m     \u001B[43mresult\u001B[49m\u001B[43m[\u001B[49m\u001B[43mrl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindexer\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m arr\n\u001B[1;32m   1795\u001B[0m     itemmask[rl\u001B[38;5;241m.\u001B[39mindexer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1797\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m itemmask\u001B[38;5;241m.\u001B[39mall():\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: '434b3925094e'"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the training dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "train_data_path = '/Users/lidanyang/deepw/code/ml_engineer/dev/data_agents_opt/data/icr-identify-age-related-conditions/split_train.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "# Step 2: Summarize the dataset\n",
    "# Get a quick overview of the dataset\n",
    "train_data.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "display(train_data.head())\n",
    "\n",
    "# Step 3: Check for missing values\n",
    "# Check for any missing values in the dataset\n",
    "missing_values = train_data.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Step 4: Explore the distribution of the target variable\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of the target variable 'Class'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Class', data=train_data)\n",
    "plt.title('Distribution of the target variable (Class)')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Explore correlations between features\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation matrix of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c963264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:15:20.130545Z",
     "iopub.status.busy": "2024-01-30T07:15:20.129336Z",
     "iopub.status.idle": "2024-01-30T07:15:21.319376Z",
     "shell.execute_reply": "2024-01-30T07:15:21.319028Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Explore correlations between features\n",
    "import numpy as np\n",
    "\n",
    "# Select only numeric columns for correlation\n",
    "numeric_columns = train_data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "numeric_correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(numeric_correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation matrix of features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb89c1c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:15:24.873459Z",
     "iopub.status.busy": "2024-01-30T07:15:24.873027Z",
     "iopub.status.idle": "2024-01-30T07:15:25.430607Z",
     "shell.execute_reply": "2024-01-30T07:15:25.430325Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:24.969 | INFO     | metagpt.const:get_metagpt_package_root:32 - Package root set to /Users/lidanyang/deepw/code/ml_engineer/ci/data_agents_opt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.007 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type eda registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.008 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type data_preprocess registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.009 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type feature_engineering registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.009 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type model_train registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.010 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type model_evaluate registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.011 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type stable_diffusion registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.011 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type image2webpage registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.012 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type web_scraping registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.013 | INFO     | metagpt.tools.tool_registry:register_tool_type:29 - tool type other registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.102 | INFO     | metagpt.tools.tool_registry:register_tool:71 - FillMissingValue registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.107 | INFO     | metagpt.tools.tool_registry:register_tool:71 - MinMaxScale registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.111 | INFO     | metagpt.tools.tool_registry:register_tool:71 - StandardScale registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.116 | INFO     | metagpt.tools.tool_registry:register_tool:71 - MaxAbsScale registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.120 | INFO     | metagpt.tools.tool_registry:register_tool:71 - RobustScale registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.125 | INFO     | metagpt.tools.tool_registry:register_tool:71 - OrdinalEncode registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.129 | INFO     | metagpt.tools.tool_registry:register_tool:71 - OneHotEncode registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.134 | INFO     | metagpt.tools.tool_registry:register_tool:71 - LabelEncode registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.165 | INFO     | metagpt.tools.tool_registry:register_tool:71 - PolynomialExpansion registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.170 | INFO     | metagpt.tools.tool_registry:register_tool:71 - CatCount registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.175 | INFO     | metagpt.tools.tool_registry:register_tool:71 - TargetMeanEncoder registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.181 | INFO     | metagpt.tools.tool_registry:register_tool:71 - KFoldTargetMeanEncoder registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.186 | INFO     | metagpt.tools.tool_registry:register_tool:71 - CatCross registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.192 | INFO     | metagpt.tools.tool_registry:register_tool:71 - GroupStat registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.198 | INFO     | metagpt.tools.tool_registry:register_tool:71 - SplitBins registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.204 | INFO     | metagpt.tools.tool_registry:register_tool:71 - GeneralSelection registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.211 | INFO     | metagpt.tools.tool_registry:register_tool:71 - VarianceBasedSelection registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.370 | INFO     | metagpt.tools.tool_registry:register_tool:71 - SDEngine registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.375 | INFO     | metagpt.tools.tool_registry:register_tool:71 - GPTvGenerator registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 15:15:25.428 | INFO     | metagpt.tools.tool_registry:register_tool:71 - scrape_web_playwright registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_info\n",
      "{'Category': ['Id', 'EJ'], 'Numeric': ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'], 'Datetime': [], 'Others': []}\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.data_preprocess import get_column_info\n",
    "\n",
    "column_info = get_column_info(train_data)\n",
    "print(\"column_info\")\n",
    "print(column_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18094869",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:15:45.160716Z",
     "iopub.status.busy": "2024-01-30T07:15:45.159985Z",
     "iopub.status.idle": "2024-01-30T07:15:45.212949Z",
     "shell.execute_reply": "2024-01-30T07:15:45.212468Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Make a copy of the datasets\u001B[39;00m\n\u001B[1;32m      5\u001B[0m copy_train_data \u001B[38;5;241m=\u001B[39m train_data\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m----> 6\u001B[0m copy_eval_data \u001B[38;5;241m=\u001B[39m \u001B[43meval_data\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Fill missing values for numeric columns\u001B[39;00m\n\u001B[1;32m      9\u001B[0m numeric_features \u001B[38;5;241m=\u001B[39m copy_train_data\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39m[np\u001B[38;5;241m.\u001B[39mnumber])\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'eval_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Fill missing values\n",
    "from metagpt.tools.libs.data_preprocess import FillMissingValue\n",
    "\n",
    "# Make a copy of the datasets\n",
    "copy_train_data = train_data.copy()\n",
    "copy_eval_data = eval_data.copy()\n",
    "\n",
    "# Fill missing values for numeric columns\n",
    "numeric_features = copy_train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "fill_missing_numeric = FillMissingValue(features=numeric_features, strategy='mean')\n",
    "fill_missing_numeric.fit(copy_train_data)\n",
    "copy_train_data = fill_missing_numeric.transform(copy_train_data)\n",
    "copy_eval_data = fill_missing_numeric.transform(copy_eval_data)\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "categorical_features = ['EJ']\n",
    "fill_missing_categorical = FillMissingValue(features=categorical_features, strategy='most_frequent')\n",
    "fill_missing_categorical.fit(copy_train_data)\n",
    "copy_train_data = fill_missing_categorical.transform(copy_train_data)\n",
    "copy_eval_data = fill_missing_categorical.transform(copy_eval_data)\n",
    "\n",
    "# Step 2: Scale numerical features\n",
    "from metagpt.tools.libs.data_preprocess import MinMaxScale\n",
    "\n",
    "# Exclude the target column 'Class' from scaling\n",
    "scaling_features = [feature for feature in numeric_features if feature != 'Class']\n",
    "minmax_scale = MinMaxScale(features=scaling_features)\n",
    "minmax_scale.fit(copy_train_data)\n",
    "copy_train_data = minmax_scale.transform(copy_train_data)\n",
    "copy_eval_data = minmax_scale.transform(copy_eval_data)\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "from metagpt.tools.libs.data_preprocess import LabelEncode\n",
    "\n",
    "# Apply label encoding to the categorical feature 'EJ'\n",
    "label_encode = LabelEncode(features=categorical_features)\n",
    "label_encode.fit(copy_train_data)\n",
    "copy_train_data = label_encode.transform(copy_train_data)\n",
    "copy_eval_data = label_encode.transform(copy_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9476fa38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:16:37.677601Z",
     "iopub.status.busy": "2024-01-30T07:16:37.677077Z",
     "iopub.status.idle": "2024-01-30T07:16:37.713736Z",
     "shell.execute_reply": "2024-01-30T07:16:37.713377Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load the evaluation dataset\n",
    "import pandas as pd\n",
    "\n",
    "eval_data_path = '/Users/lidanyang/deepw/code/ml_engineer/dev/data_agents_opt/data/icr-identify-age-related-conditions/split_eval.csv'\n",
    "eval_data = pd.read_csv(eval_data_path)\n",
    "\n",
    "# Make a copy of the datasets\n",
    "copy_train_data = train_data.copy()\n",
    "copy_eval_data = eval_data.copy()\n",
    "\n",
    "# Fill missing values for numeric columns\n",
    "numeric_features = copy_train_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "fill_missing_numeric = FillMissingValue(features=numeric_features, strategy='mean')\n",
    "fill_missing_numeric.fit(copy_train_data)\n",
    "copy_train_data = fill_missing_numeric.transform(copy_train_data)\n",
    "copy_eval_data = fill_missing_numeric.transform(copy_eval_data)\n",
    "\n",
    "# Fill missing values for categorical columns\n",
    "categorical_features = ['EJ']\n",
    "fill_missing_categorical = FillMissingValue(features=categorical_features, strategy='most_frequent')\n",
    "fill_missing_categorical.fit(copy_train_data)\n",
    "copy_train_data = fill_missing_categorical.transform(copy_train_data)\n",
    "copy_eval_data = fill_missing_categorical.transform(copy_eval_data)\n",
    "\n",
    "# Scale numerical features\n",
    "from metagpt.tools.libs.data_preprocess import MinMaxScale\n",
    "\n",
    "# Exclude the target column 'Class' from scaling\n",
    "scaling_features = [feature for feature in numeric_features if feature != 'Class']\n",
    "minmax_scale = MinMaxScale(features=scaling_features)\n",
    "minmax_scale.fit(copy_train_data)\n",
    "copy_train_data = minmax_scale.transform(copy_train_data)\n",
    "copy_eval_data = minmax_scale.transform(copy_eval_data)\n",
    "\n",
    "# Encode categorical variables\n",
    "from metagpt.tools.libs.data_preprocess import LabelEncode\n",
    "\n",
    "# Apply label encoding to the categorical feature 'EJ'\n",
    "label_encode = LabelEncode(features=categorical_features)\n",
    "label_encode.fit(copy_train_data)\n",
    "copy_train_data = label_encode.transform(copy_train_data)\n",
    "copy_eval_data = label_encode.transform(copy_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9704c7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:16:45.213629Z",
     "iopub.status.busy": "2024-01-30T07:16:45.213272Z",
     "iopub.status.idle": "2024-01-30T07:16:45.220279Z",
     "shell.execute_reply": "2024-01-30T07:16:45.219840Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Information for Training Data:\n",
      "{'Category': ['Id'], 'Numeric': ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'], 'Datetime': [], 'Others': []}\n",
      "\n",
      "Column Information for Evaluation Data:\n",
      "{'Category': ['Id'], 'Numeric': ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BN', 'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FE', 'FI', 'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class'], 'Datetime': [], 'Others': []}\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.data_preprocess import get_column_info\n",
    "\n",
    "column_info_train = get_column_info(copy_train_data)\n",
    "column_info_eval = get_column_info(copy_eval_data)\n",
    "print(\"Column Information for Training Data:\")\n",
    "print(column_info_train)\n",
    "print(\"\\nColumn Information for Evaluation Data:\")\n",
    "print(column_info_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f866d839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:17:09.994022Z",
     "iopub.status.busy": "2024-01-30T07:17:09.993568Z",
     "iopub.status.idle": "2024-01-30T07:17:10.016646Z",
     "shell.execute_reply": "2024-01-30T07:17:10.016256Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Add polynomial and interaction features\n",
    "from metagpt.tools.libs.feature_engineering import PolynomialExpansion\n",
    "\n",
    "# List of numeric columns for polynomial expansion, excluding the 'Id' and 'Class' columns\n",
    "numeric_features_for_poly = [col for col in numeric_features if col not in ['Id', 'Class']]\n",
    "polynomial_expansion = PolynomialExpansion(cols=numeric_features_for_poly, label_col='Class')\n",
    "polynomial_expansion.fit(copy_train_data)\n",
    "copy_train_data = polynomial_expansion.transform(copy_train_data)\n",
    "copy_eval_data = polynomial_expansion.transform(copy_eval_data)\n",
    "\n",
    "# Step 2: Add value counts of a categorical column as new feature\n",
    "# Since 'EJ' is the only categorical feature, we will use it for CatCount\n",
    "from metagpt.tools.libs.feature_engineering import CatCount\n",
    "cat_count = CatCount(col='EJ')\n",
    "cat_count.fit(copy_train_data)\n",
    "copy_train_data = cat_count.transform(copy_train_data)\n",
    "copy_eval_data = cat_count.transform(copy_eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0bf67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:17:13.649541Z",
     "iopub.status.busy": "2024-01-30T07:17:13.649054Z",
     "iopub.status.idle": "2024-01-30T07:17:13.657787Z",
     "shell.execute_reply": "2024-01-30T07:17:13.657235Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_info\n",
      "{'Category': ['Id'], 'Numeric': ['AH', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD', 'BP', 'BR', 'BZ', 'CB', 'CC', 'CD', 'CF', 'CH', 'CL', 'CS', 'CU', 'CW', 'DA', 'DE', 'DF', 'DH', 'DL', 'DN', 'DV', 'DY', 'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD', 'FI', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL', 'Class', 'AF', 'DU', 'BQ', 'FL', 'FE', 'AB', 'DI', 'CR', 'AM', 'BN', 'AF^2', 'AF DU', 'AF BQ', 'AF FL', 'AF FE', 'AF AB', 'AF DI', 'AF CR', 'AF AM', 'AF BN', 'DU^2', 'DU BQ', 'DU FL', 'DU FE', 'DU AB', 'DU DI', 'DU CR', 'DU AM', 'DU BN', 'BQ^2', 'BQ FL', 'BQ FE', 'BQ AB', 'BQ DI', 'BQ CR', 'BQ AM', 'BQ BN', 'FL^2', 'FL FE', 'FL AB', 'FL DI', 'FL CR', 'FL AM', 'FL BN', 'FE^2', 'FE AB', 'FE DI', 'FE CR', 'FE AM', 'FE BN', 'AB^2', 'AB DI', 'AB CR', 'AB AM', 'AB BN', 'DI^2', 'DI CR', 'DI AM', 'DI BN', 'CR^2', 'CR AM', 'CR BN', 'AM^2', 'AM BN', 'BN^2', 'EJ_cnt'], 'Datetime': [], 'Others': []}\n"
     ]
    }
   ],
   "source": [
    "from metagpt.tools.libs.data_preprocess import get_column_info\n",
    "column_info = get_column_info(copy_train_data)\n",
    "print(\"column_info\")\n",
    "print(column_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c1c5e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:17:37.177905Z",
     "iopub.status.busy": "2024-01-30T07:17:37.177502Z",
     "iopub.status.idle": "2024-01-30T07:17:37.695614Z",
     "shell.execute_reply": "2024-01-30T07:17:37.695260Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on the evaluation data: 0.8778\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the data for training\n",
    "# Separate features and target variable\n",
    "X_train = copy_train_data.drop(['Id', 'Class'], axis=1)\n",
    "y_train = copy_train_data['Class']\n",
    "X_eval = copy_eval_data.drop(['Id', 'Class'], axis=1)\n",
    "y_eval = copy_eval_data['Class']\n",
    "\n",
    "# Step 2: Train a machine learning model\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Initialize the XGBoost Classifier\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "# Make predictions on the evaluation set\n",
    "y_pred = model.predict(X_eval)\n",
    "\n",
    "# Calculate the f1 score\n",
    "f1 = f1_score(y_eval, y_pred, average='macro')\n",
    "print(f'F1 Score on the evaluation data: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "183f2a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T07:17:50.160105Z",
     "iopub.status.busy": "2024-01-30T07:17:50.159646Z",
     "iopub.status.idle": "2024-01-30T07:17:50.177007Z",
     "shell.execute_reply": "2024-01-30T07:17:50.176419Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on the evaluation data: 0.8778\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the evaluation dataset and report the f1 score\n",
    "y_pred = model.predict(X_eval)\n",
    "f1 = f1_score(y_eval, y_pred, average='macro')\n",
    "print(f'F1 Score on the evaluation data: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}